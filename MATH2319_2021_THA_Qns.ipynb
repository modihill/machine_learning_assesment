{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MATH2319 Machine Learning\n",
    "### Semester 1, 2021\n",
    "### Take-Home Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessment Rules: Please read carefully!\n",
    "1. <font color='red'> **You are NOT allowed to access any solution materials related to any assessments from any previous offerings of this course.** </font>\n",
    "2. <font color='red'> **You must work on this assessment on your own.** </font>\n",
    "3. **For other codes of conduct and a list of authorized resources, please refer to this web page on Canvas:**<br> https://rmit.instructure.com/courses/79988/assignments/568355\n",
    "4. You must document all your work in Jupyter Notebook format. Please submit **one** Jupyter Notebook file & **one** HTML file (compiled from your notebook) **per question**. Specifically, you will need to upload the following 4 files for this assessment:\n",
    "> - StudentID_Q1.html\n",
    "> - StudentID_Q1.ipynb\n",
    "> - StudentID_Q2.html\n",
    "> - StudentID_Q2.ipynb\n",
    "5. **Please do NOT zip your submission** and **please make sure you include your full name and student ID at the top of each one of your Jupyter Notebook files.** Thank you.\n",
    "6. Depending on whether you use Excel for your solutions, you might also need to upload the following two files:\n",
    "> - StudentID_Q1.xls\n",
    "> - StudentID_Q2.xls\n",
    "7. Technical instructions you need to follow and applicable penalties are explained in detail on this page:<br>\n",
    "https://rmit.instructure.com/courses/79988/pages/online-submission-instructions\n",
    "8. Please make sure your online submission is consistent with the checklist below:<br> \n",
    "https://rmit.instructure.com/courses/79988/pages/online-submissions-checklist\n",
    "9. **Please keep your submission neatly organised and show all your work for full credit. Solutions with little to no justification will receive little to no credits.**\n",
    "10. **Please keep in mind that there are going to be penalties for any assessment instruction or specific question instruction that you do not follow.**\n",
    "11. No member of the teaching team will assist you with any issues that are directly related to your take-home assessment solutions. However, if you need help with any generic issues, please remember that you are allowed to search the Internet for generic questions, such as \"how to change column order in Pandas\" etc. Keep in mind that 99% of the time, a Google search will provide you a much faster response for your questions when compared to posting it on a discussion forum.\n",
    "12. If you run into any errors, the best course of action would be just to Google your error message.\n",
    "13. Good luck!!!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assesment Instructions\n",
    "\n",
    "This assessment contains 2 questions.\n",
    "\n",
    "Our prescribed textbook information can be found at the link below: <br>\n",
    "https://rmit.instructure.com/courses/79988/pages/course-resources?module_item_id=3006548\n",
    "\n",
    "You can access a digital version of our prescribed textbook (**FIRST** Edition) via RMIT Libraries with your student ID and password below: <br>\n",
    "https://www.rmit.edu.au/library\n",
    "\n",
    "**Please follow the additional instructions below:**\n",
    "\n",
    "**Solution Mode:** For the two questions in this assessment, you can provide your solutions using either Python or Microsoft Excel. In addition, you can use Excel for some question parts and use Python for some other question parts if that is what you would like to do - provided that you explain all your solution steps in your Notebook files. The only exception here is that you will need to use Python only for Question 1 Part (E) as explained below. \n",
    "\n",
    "If you use Excel, please read the following carefully:\n",
    "1. Upload one Excel file per question that is solved by Excel (named as required) showing all your calculations.\n",
    "2. **You will still need to explain your all solution steps in a clear fashion and present all your solutions in the required tables in your Jupyter Notebook submission file.**\n",
    "3. Marking of your work will be done based on your Jupyter Notebooks, not your Excel files (your Excel  files will be used only for verification purposes). \n",
    "4. <font color='red'>**IMPORTANT NOTE: Due to the reason stated above, you will not get any points for solutions not presented in your Jupyter Notebook (even if you submit your Excel files!).**</font>\n",
    "\n",
    "**Table Format Clarification:** Whenever we ask for a table, your table can be a Pandas data frame or a Jupyter notebook table; both formats will be accepted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "### (50 points)\n",
    "\n",
    "This question is inspired from Exercise 3 in Chapter 5 in the textbook. \n",
    "\n",
    "On Canvas, you will see a CSV file named \"THA_diamonds.csv\". This file is a small subset of a real dataset on diamond prices in a [Kaggle competition](https://www.kaggle.com/shivam2503/diamonds). You will use this dataset for this question and the next question. \n",
    "\n",
    "**Some Background Information:** In our version of the dataset, the `price` feature has been discretized as `low`, `medium`, and `high`, and `premium`. If you are interested, these levels correspond to the following price ranges in the actual diamonds dataset:\n",
    "- `low` price: price between \\\\$1000 and \\\\$2000\n",
    "- `medium` price: price between \\\\$2000 and \\\\$3000\n",
    "- `high` price: price between \\\\$3000 and \\\\$3500\n",
    "- `premium` price: price between \\\\$3500 and \\\\$4000\n",
    "\n",
    "**Question Overview:** For this question, you will use the (unweighted) KNN algorithm for predicting the `carat` (numerical) target feature for the following single observation using the **Euclidean distance** metric with different number of neighbors:\n",
    "- `cut` = good\n",
    "- `color` = D\n",
    "- `depth` = 60\n",
    "- `price` = premium\n",
    "- (`carat` = 0.71 but you will pretend that you do not have this information)\n",
    "\n",
    "In practice, you would use cross-validation or train-test split for determining optimal values of KNN hyperparameters. **However, as far as this assessment is concerned, you are to use entire data for training.**\n",
    "\n",
    "\n",
    "### Part A (15 points)\n",
    "Prepare your dataset for KNN modeling. Specifically, \n",
    "1. Perform one-hot encoding of the categorical descriptive features in the input dataset.\n",
    "2. Scale your descriptive features to be between 0 and 1.\n",
    "3. Display the **last** 10 rows after one-hot encoding and scaling.\n",
    "\n",
    "<font color='red'>**IMPORTANT NOTE: If your data preparation steps are incorrect, you will not get full credit for a correct follow-through.**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** For Parts (B), (C), and (D) below, you are **not** allowed to use the `KNeighborsRegressor()` in Scikit-Learn module, but rather use manual calculations (via either Python or Excel). That is, you will need to show and explain all your solution steps **without** using Scikit-Learn. The reason for this restriction is so that you get to learn how some things work behind the scenes. \n",
    "\n",
    "### Part B (5 points)\n",
    "What is the prediction of the 1-KNN algorithm (i.e., k=1 in KNN) for the `carat` target feature using your manual calculations (using the Euclidean distance metric) for the single observation given above?\n",
    "\n",
    "### Part C (5 points)\n",
    "What is the prediction of the 5-KNN algorithm?\n",
    "\n",
    "### Part D (5 points)\n",
    "What is the prediction of the 10-KNN algorithm?\n",
    "\n",
    "\n",
    "### Part E (15 points)\n",
    "\n",
    "This part (E) is an exception to the solution mode instructions for this question. In particular, you will need to use the `KNeighborsRegressor()` in Scikit-Learn to perform the same predictions in each Part (B) to (D). That is, \n",
    "- What is the prediction of the 1-KNN algorithm using `KNeighborsRegressor()`?\n",
    "- What is the prediction of the 5-KNN algorithm using `KNeighborsRegressor()`?\n",
    "- What is the prediction of the 10-KNN algorithm using `KNeighborsRegressor()`?\n",
    "\n",
    "Are you able to get the same results as in your manual calculations? Please explain.\n",
    "\n",
    "\n",
    "### Part F: Wrap-up (5 points)\n",
    "\n",
    "<font color='red'>**IMPORTANT NOTE: This Wrap-up section is mandatory. That is, for Parts (B) to (E) (inclusive), you will not get any points for solutions not presented in the table format explained below.**</font> \n",
    "\n",
    "Add and display two tables called **\"df_summary_manual\"** and **\"df_summary_sklearn\"** respectively:\n",
    "- For the table **\"df_summary_manual\"**, you will report your results for Parts (B) to (D) using your manual calculations.\n",
    "- For the table **\"df_summary_sklearn\"**, you will report your results for the 3 predictions in Part (E) using `KNeighborsRegressor()`.\n",
    "\n",
    "\n",
    "Each of these tables need to have the following 3 columns:\n",
    "- method\n",
    "- prediction for the observation given (to be rounded to 3 decimal places)\n",
    "- is_best (True or False - only the best prediction's is_best flag needs to be True and all the others need to be False)\n",
    "\n",
    "Your table needs to have 3 rows (one for each method) in each table that summarizes your results. These tables should look like below:\n",
    "\n",
    "|method | prediction | is_best |\n",
    "|---|---|---\n",
    "|1-KNN  | ? | ? | ? |\n",
    "|5-KNN  | ? | ? | ? |\n",
    "|10-KNN | ? | ? | ? |\n",
    "\n",
    "In case of a Pandas data frame, you can populate this data frame line by line by referring to Cell #6 in our [Pandas tutorial](https://www.featureranking.com/tutorials/python-tutorials/pandas/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "### (50 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This question is inspired from Exercise 3 in Chapter 4 in the textbook. \n",
    "\n",
    "You will use the same CSV file as in Question 1 named \"THA_diamonds.csv\". You will build a simple decision tree with **depth 1** using this dataset for predicting the `price` (categorical) target feature using the **Entropy** split criterion. \n",
    "\n",
    "To clarify, for Question 1, your target feature will be `carat` whereas for this Question 2, your target feature will be `price`.\n",
    "\n",
    "For this question, you are **allowed** to use & modify any Python code available on our website [here](https://www.featureranking.com/tutorials/machine-learning-tutorials/information-gain-computation/). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A (10 points)\n",
    "\n",
    "The dataset for this question has 2 numerical descriptive features, `carat` and `depth`. \n",
    "1. Discretize these 2 features separately as \"category_1\", \"category_2\", and \"category_3\" respectively using the *equal-frequency binning* technique. \n",
    "2. Display the first 10 rows after discretization of these two features.\n",
    "\n",
    "After this discretization, all features in your dataset will be categorical (which we will assume to be **\"nominal categorical\"**). \n",
    "\n",
    "For this question, please do **NOT** perform any one-hot-encoding of the categorical descriptive features nor any scaling. Also, please do **NOT** perform any train-test splits.\n",
    "\n",
    "<font color='red'>**IMPORTANT NOTE: If your discretizations are incorrect, you will not get full credit for a correct follow-through.**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B (5 points)\n",
    "\n",
    "Compute the impurity of the `price` target feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C (20 points)\n",
    "\n",
    "<font color='red'>**IMPORTANT NOTE: For Parts C and D below, you will not get any points for solutions not presented in the required table format.**</font> \n",
    "\n",
    "In this part, you will determine the root node for your decision tree.\n",
    "\n",
    "Your answer to this part needs to be a table and it needs to be called **\"df_splits\"**. Also, it needs to have the following 4 columns:\n",
    "- split\n",
    "- remainder\n",
    "- info_gain\n",
    "- is_optimal (True or False - only the optimal split's is_optimal flag needs to be True and the others need to be False)\n",
    "\n",
    "In your **\"df_splits\"** table, you should have **one row for each descriptive feature in the dataset**. As an example for your **\"df_splits\"** table, consider the `spam prediction` example in Table 4.2 in the textbook (**FIRST** Edition) on page 121, which was also covered in lectorials. The `df_splits` table would look something like the table below.\n",
    "\n",
    "|split| remainder | info_gain| is_optimal |\n",
    "|---|---|---|---|\n",
    "|suspicious words | ? | ? | True |\n",
    "|unknown sender | ? | ? | False |\n",
    "|contains images | ? | ? | False |\n",
    "\n",
    "**HINT:** Your `df_splits` table should have 4 rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part D (15 points)\n",
    "\n",
    "In this part, you will **assume** the `carat` descriptive feature is at the root node (**NOTE:** This feature may or may not be the optimal root node, but you will just assume it is). Under this assumption, you will make predictions for the `price` target variable. \n",
    "\n",
    "Your answer to this part needs to be a table and it needs to be called **\"df_pred\"**. Also, it needs to have the following 6 columns:\n",
    "- leaf_condition\n",
    "- low_price_prob (probability)\n",
    "- medium_price_prob\n",
    "- high_price_prob\n",
    "- premium_price_prob\n",
    "- leaf_prediction\n",
    "\n",
    "As an example, continuing the spam prediction problem, assume the `suspicious words` descriptive feature is at the root node. The `df_pred` table would look something like the table below.\n",
    "\n",
    "|leaf_condition| spam_prob | ham_prob | leaf_prediction |\n",
    "|---|---|---|---|\n",
    "|suspicious words == true | ? | ? | ? |\n",
    "|suspicious words == false | ? | ? | ? |\n",
    "\n",
    "**HINT:** Your `df_pred` table should have 3 rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "www.featureranking.com"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
